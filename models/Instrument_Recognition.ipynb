{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load pand split data\n",
    "df = pd.read_csv(r'Data\\IRMAS_features_2_sec.csv')\n",
    "x = df.drop(columns=[\"file_name\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42) #80% Training, 20% testing\n",
    "\n",
    "print(f\"Training set size: {x_train.shape}\")\n",
    "print(f\"Test set size: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Encode labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "#simple neural network model definition\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(label_encoder.classes_), activation='softmax') #output layer\n",
    "])\n",
    "#Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "history = model.fit(x_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Evaluate model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Model evaluation\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1) #predictions on test set\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_)) #Generate calssification report\n",
    "print(confusion_matrix(y_test_encoded, y_pred)) #Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuaracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Plot Loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained model in HDF% formate\n",
    "model.save('Instrument_model.h5')\n",
    "\n",
    "# Save the label encoder classes (the instrument classes)\n",
    "import numpy as np\n",
    "np.save('Instrument_classes.npy', label_encoder.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
